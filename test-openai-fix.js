// Test and fix OpenAI API issues
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

console.log('üîß DIAGN√ìSTICO OPENAI API');
console.log('========================');

async function testOpenAIModels() {
  console.log('üìã Testando modelos dispon√≠veis...');
  
  try {
    const models = await openai.models.list();
    console.log(`‚úÖ ${models.data.length} modelos encontrados`);
    
    // List available GPT models
    const gptModels = models.data
      .filter(model => model.id.includes('gpt'))
      .map(model => model.id)
      .sort();
    
    console.log('ü§ñ Modelos GPT dispon√≠veis:');
    gptModels.forEach(model => console.log(`  - ${model}`));
    
    return gptModels;
  } catch (error) {
    console.log('‚ùå Erro ao listar modelos:', error.message);
    return [];
  }
}

async function testModelAccess(model) {
  console.log(`\nüß™ Testando modelo: ${model}`);
  
  try {
    const response = await openai.chat.completions.create({
      model: model,
      messages: [{ role: 'user', content: 'Ol√°, apenas responda "OK"' }],
      max_tokens: 5,
      temperature: 0
    });
    
    const result = response.choices[0].message.content;
    console.log(`‚úÖ ${model}: ${result}`);
    return true;
  } catch (error) {
    console.log(`‚ùå ${model}: ${error.message}`);
    return false;
  }
}

async function findWorkingModel() {
  console.log('\nüîç Procurando modelo funcional...');
  
  // Test common models in order of preference
  const modelsToTest = [
    'gpt-4o-mini',
    'gpt-4o', 
    'gpt-4-turbo',
    'gpt-4',
    'gpt-3.5-turbo'
  ];
  
  for (const model of modelsToTest) {
    const works = await testModelAccess(model);
    if (works) {
      console.log(`\nüéØ MODELO FUNCIONAL ENCONTRADO: ${model}`);
      return model;
    }
  }
  
  console.log('\n‚ùå Nenhum modelo funcional encontrado');
  return null;
}

async function testOpenAIComplete() {
  console.log('üèÅ Teste completo da OpenAI API...\n');
  
  // 1. Test models list
  const availableModels = await testOpenAIModels();
  
  // 2. Find working model
  const workingModel = await findWorkingModel();
  
  // 3. Test financial analysis
  if (workingModel) {
    console.log('\nüí∞ Testando an√°lise financeira...');
    
    try {
      const response = await openai.chat.completions.create({
        model: workingModel,
        messages: [{
          role: 'user',
          content: 'Analise esta situa√ß√£o financeira: Renda: R$ 5000, Gastos: R$ 3000, Poupan√ßa: R$ 500. D√™ um score de 0-100.'
        }],
        max_tokens: 200,
        temperature: 0.7
      });
      
      const analysis = response.choices[0].message.content;
      console.log('‚úÖ An√°lise financeira funcionando:');
      console.log(analysis.substring(0, 200) + '...');
      
      return { workingModel, analysis };
    } catch (error) {
      console.log(`‚ùå Erro na an√°lise: ${error.message}`);
      return { workingModel, analysis: null };
    }
  }
  
  return { workingModel: null, analysis: null };
}

// Run the complete test
testOpenAIComplete()
  .then(result => {
    console.log('\nüéØ RESULTADO FINAL:');
    console.log('===================');
    
    if (result.workingModel) {
      console.log(`‚úÖ OpenAI funcionando com modelo: ${result.workingModel}`);
      console.log('‚úÖ An√°lise financeira: OK');
      console.log('\nüîß CORRE√á√ÉO NECESS√ÅRIA:');
      console.log(`Alterar modelo no multi-llm-orchestrator.ts para: ${result.workingModel}`);
    } else {
      console.log('‚ùå OpenAI n√£o funcionando');
      console.log('üîß Verificar:');
      console.log('1. API key v√°lida');
      console.log('2. Cr√©ditos dispon√≠veis');
      console.log('3. Permiss√µes do projeto');
    }
  })
  .catch(console.error);